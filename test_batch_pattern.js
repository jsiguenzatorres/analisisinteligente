// Script para probar el patr√≥n de lotes exitoso del DataUploadFlow

console.log("üîß INICIANDO PRUEBAS DEL PATR√ìN DE LOTES");

// Simular el patr√≥n exitoso de DataUploadFlow
async function testBatchPattern() {
    console.log("üì¶ PROBANDO PATR√ìN DE LOTES EXITOSO...");
    
    const BATCH_SIZE = 25; // Como en DataUploadFlow
    const MAX_BATCH_RETRIES = 3;
    const BATCH_DELAY = 800; // 800ms entre lotes
    
    // Simular datos grandes
    const totalRecords = 1000;
    const mockData = Array.from({ length: totalRecords }, (_, i) => ({
        id: `record-${i}`,
        value: Math.random() * 10000
    }));
    
    console.log(`üìä Datos simulados: ${totalRecords} registros`);
    
    // Crear lotes
    const batches = [];
    for (let i = 0; i < mockData.length; i += BATCH_SIZE) {
        const chunk = mockData.slice(i, i + BATCH_SIZE);
        batches.push(chunk);
    }
    
    console.log(`üì¶ Creados ${batches.length} lotes de ${BATCH_SIZE} registros`);
    
    // Procesar lotes secuencialmente (como DataUploadFlow)
    let completedBatches = 0;
    let totalProcessed = 0;
    
    for (const [idx, batch] of batches.entries()) {
        console.log(`‚è≥ Procesando lote ${idx + 1}/${batches.length} (${batch.length} registros)...`);
        
        let batchSuccess = false;
        let batchRetries = 0;
        
        while (!batchSuccess && batchRetries < MAX_BATCH_RETRIES) {
            try {
                // Simular procesamiento del lote
                await simulateBatchProcessing(batch, idx);
                batchSuccess = true;
                totalProcessed += batch.length;
                
            } catch (batchErr) {
                batchRetries++;
                console.warn(`‚ö†Ô∏è Lote ${idx + 1} fall√≥ (Intento ${batchRetries}/${MAX_BATCH_RETRIES})`);
                
                if (batchRetries >= MAX_BATCH_RETRIES) {
                    throw new Error(`Fallo definitivo en lote ${idx + 1} tras ${MAX_BATCH_RETRIES} intentos`);
                }
                
                const waitTime = 1000 * Math.pow(2, batchRetries - 1);
                console.log(`üîÑ Reintentando en ${waitTime/1000}s...`);
                await new Promise(resolve => setTimeout(resolve, waitTime));
            }
        }
        
        completedBatches++;
        const progress = Math.round(((idx + 1) / batches.length) * 100);
        console.log(`üìà Progreso: ${progress}% (${totalProcessed}/${totalRecords} registros)`);
        
        // Pausa entre lotes (como DataUploadFlow)
        if (idx < batches.length - 1) {
            await new Promise(resolve => setTimeout(resolve, BATCH_DELAY));
        }
    }
    
    console.log(`‚úÖ Patr√≥n completado: ${completedBatches}/${batches.length} lotes, ${totalProcessed} registros`);
    
    return {
        success: completedBatches === batches.length,
        processedRecords: totalProcessed,
        totalBatches: batches.length,
        completedBatches
    };
}

// Simular procesamiento de un lote con posibles fallos
async function simulateBatchProcessing(batch, batchIndex) {
    // Simular tiempo de procesamiento
    const processingTime = 100 + Math.random() * 200;
    await new Promise(resolve => setTimeout(resolve, processingTime));
    
    // Simular fallos ocasionales (10% de probabilidad)
    if (Math.random() < 0.1) {
        throw new Error(`Fallo simulado en lote ${batchIndex + 1}`);
    }
    
    // Simular √©xito
    return { success: true, processed: batch.length };
}

// Probar el patr√≥n de carga por offset (como el nuevo SamplingWorkspace)
async function testOffsetPattern() {
    console.log("üîÑ PROBANDO PATR√ìN DE OFFSET (NUEVO)...");
    
    const BATCH_SIZE = 1000;
    const MAX_BATCHES = 10;
    const totalRecords = 5000; // Simular poblaci√≥n de 5k registros
    
    let allRows = [];
    let offset = 0;
    let hasMore = true;
    let batchCount = 0;
    
    while (hasMore && batchCount < MAX_BATCHES) {
        console.log(`üì¶ Cargando lote ${batchCount + 1} (offset: ${offset})...`);
        
        try {
            // Simular llamada a API con offset
            const batchRows = await simulateOffsetQuery(offset, BATCH_SIZE, totalRecords);
            
            if (!batchRows || batchRows.length === 0) {
                hasMore = false;
                break;
            }
            
            allRows = allRows.concat(batchRows);
            offset += BATCH_SIZE;
            batchCount++;
            
            // Si el lote es menor que BATCH_SIZE, es el √∫ltimo
            if (batchRows.length < BATCH_SIZE) {
                hasMore = false;
            }
            
            // Pausa peque√±a entre lotes
            await new Promise(resolve => setTimeout(resolve, 200));
            
        } catch (error) {
            console.error(`‚ùå Error en lote ${batchCount + 1}:`, error);
            hasMore = false;
        }
    }
    
    console.log(`‚úÖ Patr√≥n offset completado: ${allRows.length} registros en ${batchCount} lotes`);
    
    return {
        success: allRows.length > 0,
        totalRecords: allRows.length,
        batchesUsed: batchCount
    };
}

// Simular consulta con offset
async function simulateOffsetQuery(offset, limit, totalRecords) {
    // Simular tiempo de consulta
    await new Promise(resolve => setTimeout(resolve, 50 + Math.random() * 100));
    
    // Calcular registros disponibles desde el offset
    const availableRecords = Math.max(0, totalRecords - offset);
    const recordsToReturn = Math.min(limit, availableRecords);
    
    if (recordsToReturn === 0) {
        return [];
    }
    
    // Generar registros simulados
    return Array.from({ length: recordsToReturn }, (_, i) => ({
        id: `record-${offset + i}`,
        value: Math.random() * 10000
    }));
}

// Comparar ambos patrones
async function compareBatchPatterns() {
    console.log("‚öñÔ∏è COMPARANDO PATRONES DE LOTES...\n");
    
    const startTime = Date.now();
    
    // Probar patr√≥n original (DataUploadFlow)
    console.log("1Ô∏è‚É£ PATR√ìN ORIGINAL (DataUploadFlow):");
    const originalResult = await testBatchPattern();
    const originalTime = Date.now() - startTime;
    
    console.log("\n2Ô∏è‚É£ PATR√ìN NUEVO (Offset):");
    const offsetStartTime = Date.now();
    const offsetResult = await testOffsetPattern();
    const offsetTime = Date.now() - offsetStartTime;
    
    console.log("\nüìä COMPARACI√ìN DE RESULTADOS:");
    console.table({
        'Patr√≥n Original': {
            '√âxito': originalResult.success ? '‚úÖ' : '‚ùå',
            'Registros': originalResult.processedRecords,
            'Lotes': originalResult.completedBatches,
            'Tiempo (ms)': originalTime
        },
        'Patr√≥n Offset': {
            '√âxito': offsetResult.success ? '‚úÖ' : '‚ùå',
            'Registros': offsetResult.totalRecords,
            'Lotes': offsetResult.batchesUsed,
            'Tiempo (ms)': offsetTime
        }
    });
    
    // Recomendaci√≥n
    if (originalResult.success && offsetResult.success) {
        console.log("‚úÖ AMBOS PATRONES FUNCIONAN");
        console.log("üí° Recomendaci√≥n: Usar patr√≥n original para uploads, offset para consultas grandes");
    } else if (originalResult.success) {
        console.log("‚ö†Ô∏è SOLO EL PATR√ìN ORIGINAL FUNCIONA");
        console.log("üí° Recomendaci√≥n: Aplicar patr√≥n DataUploadFlow al muestreo");
    } else if (offsetResult.success) {
        console.log("‚ö†Ô∏è SOLO EL PATR√ìN OFFSET FUNCIONA");
        console.log("üí° Recomendaci√≥n: Usar patr√≥n offset para consultas grandes");
    } else {
        console.log("‚ùå AMBOS PATRONES FALLARON");
        console.log("üí° Recomendaci√≥n: Revisar configuraci√≥n de red y timeouts");
    }
}

// Funci√≥n para diagnosticar problemas espec√≠ficos del MUS
function diagnoseMUSProblems() {
    console.log("üîç DIAGN√ìSTICO ESPEC√çFICO PARA MUS:");
    
    const problems = [
        {
            problem: "Bucle infinito en selecci√≥n",
            cause: "Consulta muy grande sin lotes",
            solution: "Aplicar patr√≥n de lotes del DataUploadFlow"
        },
        {
            problem: "Timeout en get_universe",
            cause: "Poblaci√≥n muy grande (>10k registros)",
            solution: "Usar offset con lotes de 1000 registros"
        },
        {
            problem: "Memoria insuficiente",
            cause: "Cargar todos los registros de una vez",
            solution: "Procesar por lotes con pausas"
        },
        {
            problem: "Error de red intermitente",
            cause: "Conexi√≥n inestable",
            solution: "Reintentos autom√°ticos con backoff exponencial"
        }
    ];
    
    console.table(problems);
    
    console.log("\nüîß PASOS PARA RESOLVER MUS:");
    console.log("1. Aplicar patr√≥n de lotes del DataUploadFlow");
    console.log("2. Usar offset para consultas grandes");
    console.log("3. Implementar reintentos autom√°ticos");
    console.log("4. Agregar pausas entre lotes");
    console.log("5. Limitar tama√±o m√°ximo de poblaci√≥n");
}

// Ejecutar todas las pruebas
async function runBatchTests() {
    console.log("üöÄ EJECUTANDO PRUEBAS COMPLETAS DE LOTES...\n");
    
    try {
        await compareBatchPatterns();
        console.log("\n");
        diagnoseMUSProblems();
        
        console.log("\nüéØ CONCLUSI√ìN:");
        console.log("El patr√≥n de lotes del DataUploadFlow es EXITOSO y debe aplicarse al muestreo");
        console.log("Esto deber√≠a resolver el bucle infinito del MUS");
        
    } catch (error) {
        console.error("‚ùå Error en las pruebas:", error);
    }
}

// Exportar para uso en consola
window.testBatchPattern = {
    runBatchTests,
    testBatchPattern,
    testOffsetPattern,
    compareBatchPatterns,
    diagnoseMUSProblems
};

console.log("üéØ Pruebas de lotes cargadas. Ejecuta: testBatchPattern.runBatchTests()");